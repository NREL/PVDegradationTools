{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# TEST\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pvdeg\n",
    "from pytest import approx\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "\n",
    "# Load weather data\n",
    "WEATHER = pd.read_csv(\n",
    "    os.path.join(TEST_DATA_DIR, \"weather_day_pytest.csv\"), index_col=0, parse_dates=True\n",
    ")\n",
    "with open(os.path.join(TEST_DATA_DIR, \"meta.json\"), \"r\") as file:\n",
    "    META = json.load(file)\n",
    "\n",
    "# Load expected results\n",
    "rh_expected = pd.read_csv(\n",
    "    os.path.join(TEST_DATA_DIR, \"input_day_pytest.csv\"), index_col=0, parse_dates=True\n",
    ")\n",
    "rh_cols = [col for col in rh_expected.columns if \"RH\" in col]\n",
    "rh_expected = rh_expected[rh_cols]\n",
    "\n",
    "\n",
    "def test_module():\n",
    "    \"\"\"\n",
    "    test pvdeg.humidity.calc_rel_humidity\n",
    "\n",
    "    Requires:\n",
    "    ---------\n",
    "    weather dataframe and meta dictionary\n",
    "    \"\"\"\n",
    "    result = pvdeg.humidity.module(WEATHER, META)\n",
    "    pd.testing.assert_frame_equal(result, rh_expected, check_dtype=False)\n",
    "\n",
    "\n",
    "def test_psat():\n",
    "    \"\"\"\n",
    "    test pvdeg.humidity.psat\n",
    "\n",
    "    Requires:\n",
    "    ---------\n",
    "    weahter dataframe and meta dictionary\n",
    "    \"\"\"\n",
    "    psat_avg = pvdeg.humidity.psat(temp=WEATHER[\"temp_air\"])[1]\n",
    "    assert psat_avg == approx(0.47607, abs=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_psat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvdeg\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "\n",
    "GEO_META = pd.read_csv(os.path.join(TEST_DATA_DIR, \"summit-meta.csv\"), index_col=0)\n",
    "with open(os.path.join(TEST_DATA_DIR, \"summit-weather.pkl\"), \"rb\") as f:\n",
    "    GEO_WEATHER = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autotemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotemplate_result = pvdeg.geospatial.auto_template(\n",
    "    func=pvdeg.humidity.module, ds_gids=GEO_WEATHER\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_template = xr.open_dataset(\n",
    "    os.path.join(TEST_DATA_DIR, \"humidity_template.nc\")\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datasets(ds1: xr.Dataset, ds2: xr.Dataset, atol=1e-10) -> bool:\n",
    "    \"\"\"Compare loaded datasets with \"empty-like\" values\"\"\"\n",
    "\n",
    "    if ds1.dims != ds2.dims:\n",
    "        return False\n",
    "\n",
    "    if set(ds1.coords.keys()) != set(ds2.coords.keys()):\n",
    "        return False\n",
    "\n",
    "    for coord in ds1.coords:\n",
    "        if ds1.coords[coord].dtype.kind in {\"i\", \"f\"}:\n",
    "            # Use np.allclose for numeric coordinates\n",
    "            if not np.allclose(ds1.coords[coord], ds2.coords[coord], atol=atol):\n",
    "                return False\n",
    "        elif ds1.coords[coord].dtype.kind == \"M\":  # datetime64 type\n",
    "            # Use array equality for datetime coordinates\n",
    "            if not np.array_equal(ds1.coords[coord], ds2.coords[coord]):\n",
    "                return False\n",
    "        else:\n",
    "            if not np.array_equal(ds1.coords[coord], ds2.coords[coord]):\n",
    "                return False\n",
    "\n",
    "    if set(ds1.data_vars.keys()) != set(ds2.data_vars.keys()):\n",
    "        return False\n",
    "\n",
    "    for var in ds1.data_vars:\n",
    "        if not np.allclose(ds1[var], ds2[var], atol=atol):\n",
    "            return False\n",
    "\n",
    "    for dim in ds1.dims:\n",
    "        if not ds1.indexes[dim].equals(ds2.indexes[dim]):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pvdeg.utilities.compare_datasets(autotemplate_result, humidity_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    \"RH_surface_outside\": (\"gid\", \"time\"),\n",
    "    \"RH_front_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_back_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_backsheet\": (\"gid\", \"time\"),\n",
    "}\n",
    "\n",
    "manual_template = pvdeg.geospatial.output_template(\n",
    "    shapes=shapes, ds_gids=GEO_WEATHER\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdeg.utilities.compare_datasets(manual_template, humidity_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test template\n",
    "\n",
    "shapes = {\"testA\": (\"gid\",), \"testB\": (\"gid\", \"time\")}\n",
    "\n",
    "template = pvdeg.geospatial.output_template(\n",
    "    shapes=shapes,\n",
    "    ds_gids=GEO_WEATHER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.to_netcdf(os.path.join(TEST_DATA_DIR, \"mismatch-template.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvdeg\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "GEO_META = pd.read_csv(os.path.join(TEST_DATA_DIR, \"summit-meta.csv\"), index_col=0)\n",
    "\n",
    "with open(os.path.join(TEST_DATA_DIR, \"summit-weather.pkl\"), \"rb\") as f:\n",
    "    GEO_WEATHER = pickle.load(f).compute().load()\n",
    "\n",
    "HUMIDITY_TEMPLATE = xr.open_dataset(\n",
    "    os.path.join(TEST_DATA_DIR, \"humidity_template.nc\"), engine=\"h5netcdf\"\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_WEATHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_WEATHER.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMIDITY_TEMPLATE.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    \"RH_surface_outside\": (\"gid\", \"time\"),\n",
    "    \"RH_front_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_back_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_backsheet\": (\"gid\", \"time\"),\n",
    "}\n",
    "\n",
    "# falsely assigning chunks here\n",
    "manual_template = pvdeg.geospatial.output_template(shapes=shapes, ds_gids=GEO_WEATHER)\n",
    "\n",
    "assert pvdeg.utilities.compare_templates(manual_template, HUMIDITY_TEMPLATE)\n",
    "for k, v in manual_template.chunks.items():\n",
    "    if len(v) != 1:\n",
    "        raise ValueError(f\"\"\"\n",
    "                          Need one chunk per axis for an unchunked input\n",
    "                          dimension {k} has {len(v)} chunks.\n",
    "                          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_weather = GEO_WEATHER.chunk({\"gid\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMIDITY_TEMPLATE.chunk({\"gid\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdeg.utilities.compare_templates(chunked_template, HUMIDITY_TEMPLATE.chunk({\"gid\": 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_template = pvdeg.geospatial.auto_template(\n",
    "    ds_gids=chunked_weather, func=pvdeg.humidity.module\n",
    ")\n",
    "\n",
    "geo_res = pvdeg.geospatial.analysis(\n",
    "    weather_ds=chunked_weather,\n",
    "    meta_df=GEO_META,\n",
    "    func=pvdeg.humidity.module,\n",
    "    template=chunked_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_res = pvdeg.geospatial.analysis(\n",
    "    chunked_weather,\n",
    "    meta_df=GEO_META,\n",
    "    func=pvdeg.humidity.module,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ds = pvdeg.geospatial.analysis(\n",
    "    weather_ds=GEO_WEATHER,\n",
    "    meta_df=GEO_META,\n",
    "    func=pvdeg.standards.standoff,\n",
    ")\n",
    "\n",
    "data_var = res_ds[\"x\"]\n",
    "\n",
    "# Stack the latitude and longitude coordinates into a single dimension\n",
    "# convert to dataframe, this can be done with xr.dataset.to_dataframe as well\n",
    "stacked = data_var.stack(z=(\"latitude\", \"longitude\"))\n",
    "latitudes = stacked[\"latitude\"].values\n",
    "longitudes = stacked[\"longitude\"].values\n",
    "data_values = stacked.values\n",
    "combined_array = np.column_stack((latitudes, longitudes, data_values))\n",
    "\n",
    "res = pd.DataFrame(combined_array).dropna()\n",
    "ans = pd.read_csv(os.path.join(TEST_DATA_DIR, \"summit-standoff-res.csv\"), index_col=0)\n",
    "res.columns = ans.columns\n",
    "\n",
    "# pd.testing.assert_frame_equal(res, ans, check_dtype=False, check_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ds.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion TESTing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import pvdeg\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER = pd.read_csv(\n",
    "    os.path.join(TEST_DATA_DIR, \"weather_day_pytest.csv\"), index_col=0, parse_dates=True\n",
    ")\n",
    "with open(os.path.join(TEST_DATA_DIR, \"meta.json\"), \"r\") as file:\n",
    "    META = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "META"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = pvdeg.temperature.temperature(\n",
    "    weather_df=WEATHER,\n",
    "    meta=META,\n",
    "    cell_or_mod=\"module\", \n",
    "    temp_model=\"sapm\",\n",
    "    conf=\"open_rack_glass_polymer\",\n",
    ")\n",
    "\n",
    "temperature = pd.DataFrame(temperature, columns = ['module_temperature'])\n",
    "temperature['time'] = list(range(len(temperature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure = 0.2109 * (1 - 0.0065 * META['altitude'] / 288.15) ** 5.25588\n",
    "\n",
    "oxygen_profile = pvdeg.diffusion.esdiffusion(\n",
    "    temperature=temperature, \n",
    "    edge_seal='OX005', \n",
    "    encapsulant='OX003', \n",
    "    edge_seal_width=1.5, \n",
    "    encapsulant_width=10, \n",
    "    seal_nodes=20, \n",
    "    encapsulant_nodes=50, \n",
    "    press=pressure, \n",
    "    repeat=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen_profile.to_csv(\"1d-oxygen-profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(os.path.join(TEST_DATA_DIR, \"1d-oxygen-profile.csv\"), index_col=0, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "col_list = copy(res.columns).values\n",
    "col_list[21] = \"1.5\"\n",
    "\n",
    "res.columns = col_list.astype(float)\n",
    "\n",
    "res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(\n",
    "    oxygen_profile, res, \n",
    "    check_dtype=False, \n",
    "    check_column_type=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Kempe Gap Calc broken file changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pvdeg.scenario import Scenario\n",
    "from pvdeg.standards import standoff\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import json\n",
    "import pandas as pd\n",
    "import pytest\n",
    "import os\n",
    "\n",
    "# problems with scenario creating directory in test directory?\n",
    "EMAIL = \"user@mail.com\"\n",
    "API_KEY = \"DEMO_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Scenario_add():\n",
    "\n",
    "    a = Scenario(name=\"test\")\n",
    "    a.clean()\n",
    "    a.restore_credentials(email=EMAIL, api_key=API_KEY)\n",
    "    a.addLocation(lat_long=(40.63336, -73.99458))\n",
    "    a.addModule(module_name=\"test-module\")\n",
    "    a.addJob(func=standoff, func_kwarg={\"wind_factor\": 0.35})\n",
    "\n",
    "    restored = Scenario.load_json(\n",
    "        file_path=os.path.join(TEST_DATA_DIR, \"test-scenario.json\")\n",
    "    )\n",
    "\n",
    "    a.path, restored.path = None, None\n",
    "    a.file, restored.file = None, None\n",
    "\n",
    "    assert a == restored"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
