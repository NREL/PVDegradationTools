{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# TEST\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pvdeg\n",
    "from pytest import approx\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "\n",
    "# Load weather data\n",
    "WEATHER = pd.read_csv(\n",
    "    os.path.join(TEST_DATA_DIR, \"weather_day_pytest.csv\"), index_col=0, parse_dates=True\n",
    ")\n",
    "with open(os.path.join(TEST_DATA_DIR, \"meta.json\"), \"r\") as file:\n",
    "    META = json.load(file)\n",
    "\n",
    "# Load expected results\n",
    "rh_expected = pd.read_csv(\n",
    "    os.path.join(TEST_DATA_DIR, \"input_day_pytest.csv\"), index_col=0, parse_dates=True\n",
    ")\n",
    "rh_cols = [col for col in rh_expected.columns if \"RH\" in col]\n",
    "rh_expected = rh_expected[rh_cols]\n",
    "\n",
    "\n",
    "def test_module():\n",
    "    \"\"\"\n",
    "    test pvdeg.humidity.calc_rel_humidity\n",
    "\n",
    "    Requires:\n",
    "    ---------\n",
    "    weather dataframe and meta dictionary\n",
    "    \"\"\"\n",
    "    result = pvdeg.humidity.module(WEATHER, META)\n",
    "    pd.testing.assert_frame_equal(result, rh_expected, check_dtype=False)\n",
    "\n",
    "\n",
    "def test_psat():\n",
    "    \"\"\"\n",
    "    test pvdeg.humidity.psat\n",
    "\n",
    "    Requires:\n",
    "    ---------\n",
    "    weahter dataframe and meta dictionary\n",
    "    \"\"\"\n",
    "    psat_avg = pvdeg.humidity.psat(temp=WEATHER[\"temp_air\"])[1]\n",
    "    assert psat_avg == approx(0.47607, abs=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_psat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvdeg\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "\n",
    "GEO_META = pd.read_csv(os.path.join(TEST_DATA_DIR, \"summit-meta.csv\"), index_col=0)\n",
    "with open(os.path.join(TEST_DATA_DIR, \"summit-weather.pkl\"), \"rb\") as f:\n",
    "    GEO_WEATHER = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autotemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotemplate_result = pvdeg.geospatial.auto_template(\n",
    "    func=pvdeg.humidity.module, ds_gids=GEO_WEATHER\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_template = xr.open_dataset(\n",
    "    os.path.join(TEST_DATA_DIR, \"humidity_template.nc\")\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datasets(ds1: xr.Dataset, ds2: xr.Dataset, atol=1e-10) -> bool:\n",
    "    \"\"\"Compare loaded datasets with \"empty-like\" values\"\"\"\n",
    "\n",
    "    if ds1.dims != ds2.dims:\n",
    "        return False\n",
    "\n",
    "    if set(ds1.coords.keys()) != set(ds2.coords.keys()):\n",
    "        return False\n",
    "\n",
    "    for coord in ds1.coords:\n",
    "        if ds1.coords[coord].dtype.kind in {\"i\", \"f\"}:\n",
    "            # Use np.allclose for numeric coordinates\n",
    "            if not np.allclose(ds1.coords[coord], ds2.coords[coord], atol=atol):\n",
    "                return False\n",
    "        elif ds1.coords[coord].dtype.kind == \"M\":  # datetime64 type\n",
    "            # Use array equality for datetime coordinates\n",
    "            if not np.array_equal(ds1.coords[coord], ds2.coords[coord]):\n",
    "                return False\n",
    "        else:\n",
    "            if not np.array_equal(ds1.coords[coord], ds2.coords[coord]):\n",
    "                return False\n",
    "\n",
    "    if set(ds1.data_vars.keys()) != set(ds2.data_vars.keys()):\n",
    "        return False\n",
    "\n",
    "    for var in ds1.data_vars:\n",
    "        if not np.allclose(ds1[var], ds2[var], atol=atol):\n",
    "            return False\n",
    "\n",
    "    for dim in ds1.dims:\n",
    "        if not ds1.indexes[dim].equals(ds2.indexes[dim]):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pvdeg.utilities.compare_datasets(autotemplate_result, humidity_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    \"RH_surface_outside\": (\"gid\", \"time\"),\n",
    "    \"RH_front_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_back_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_backsheet\": (\"gid\", \"time\"),\n",
    "}\n",
    "\n",
    "manual_template = pvdeg.geospatial.output_template(\n",
    "    shapes=shapes, ds_gids=GEO_WEATHER\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdeg.utilities.compare_datasets(manual_template, humidity_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test template\n",
    "\n",
    "shapes = {\"testA\": (\"gid\",), \"testB\": (\"gid\", \"time\")}\n",
    "\n",
    "template = pvdeg.geospatial.output_template(\n",
    "    shapes=shapes,\n",
    "    ds_gids=GEO_WEATHER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.to_netcdf(os.path.join(TEST_DATA_DIR, \"mismatch-template.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvdeg\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "GEO_META = pd.read_csv(os.path.join(TEST_DATA_DIR, \"summit-meta.csv\"), index_col=0)\n",
    "\n",
    "with open(os.path.join(TEST_DATA_DIR, \"summit-weather.pkl\"), \"rb\") as f:\n",
    "    GEO_WEATHER = pickle.load(f).compute().load()\n",
    "\n",
    "HUMIDITY_TEMPLATE = xr.open_dataset(\n",
    "    os.path.join(TEST_DATA_DIR, \"humidity_template.nc\"), engine=\"h5netcdf\"\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_WEATHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_WEATHER.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMIDITY_TEMPLATE.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    \"RH_surface_outside\": (\"gid\", \"time\"),\n",
    "    \"RH_front_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_back_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_backsheet\": (\"gid\", \"time\"),\n",
    "}\n",
    "\n",
    "# falsely assigning chunks here\n",
    "manual_template = pvdeg.geospatial.output_template(shapes=shapes, ds_gids=GEO_WEATHER)\n",
    "\n",
    "assert pvdeg.utilities.compare_templates(manual_template, HUMIDITY_TEMPLATE)\n",
    "for k, v in manual_template.chunks.items():\n",
    "    if len(v) != 1:\n",
    "        raise ValueError(f\"\"\"\n",
    "                          Need one chunk per axis for an unchunked input\n",
    "                          dimension {k} has {len(v)} chunks.\n",
    "                          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_weather = GEO_WEATHER.chunk({\"gid\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMIDITY_TEMPLATE.chunk({\"gid\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdeg.utilities.compare_templates(chunked_template, HUMIDITY_TEMPLATE.chunk({\"gid\": 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_template = pvdeg.geospatial.auto_template(\n",
    "    ds_gids=chunked_weather, func=pvdeg.humidity.module\n",
    ")\n",
    "\n",
    "geo_res = pvdeg.geospatial.analysis(\n",
    "    weather_ds=chunked_weather,\n",
    "    meta_df=GEO_META,\n",
    "    func=pvdeg.humidity.module,\n",
    "    template=chunked_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_res = pvdeg.geospatial.analysis(\n",
    "    chunked_weather,\n",
    "    meta_df=GEO_META,\n",
    "    func=pvdeg.humidity.module,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ds = pvdeg.geospatial.analysis(\n",
    "    weather_ds=GEO_WEATHER,\n",
    "    meta_df=GEO_META,\n",
    "    func=pvdeg.standards.standoff,\n",
    ")\n",
    "\n",
    "data_var = res_ds[\"x\"]\n",
    "\n",
    "# Stack the latitude and longitude coordinates into a single dimension\n",
    "# convert to dataframe, this can be done with xr.dataset.to_dataframe as well\n",
    "stacked = data_var.stack(z=(\"latitude\", \"longitude\"))\n",
    "latitudes = stacked[\"latitude\"].values\n",
    "longitudes = stacked[\"longitude\"].values\n",
    "data_values = stacked.values\n",
    "combined_array = np.column_stack((latitudes, longitudes, data_values))\n",
    "\n",
    "res = pd.DataFrame(combined_array).dropna()\n",
    "ans = pd.read_csv(os.path.join(TEST_DATA_DIR, \"summit-standoff-res.csv\"), index_col=0)\n",
    "res.columns = ans.columns\n",
    "\n",
    "# pd.testing.assert_frame_equal(res, ans, check_dtype=False, check_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ds.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion TESTing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import pvdeg\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER = pd.read_csv(\n",
    "    os.path.join(TEST_DATA_DIR, \"weather_day_pytest.csv\"), index_col=0, parse_dates=True\n",
    ")\n",
    "with open(os.path.join(TEST_DATA_DIR, \"meta.json\"), \"r\") as file:\n",
    "    META = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "META"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = pvdeg.temperature.temperature(\n",
    "    weather_df=WEATHER,\n",
    "    meta=META,\n",
    "    cell_or_mod=\"module\", \n",
    "    temp_model=\"sapm\",\n",
    "    conf=\"open_rack_glass_polymer\",\n",
    ")\n",
    "\n",
    "temperature = pd.DataFrame(temperature, columns = ['module_temperature'])\n",
    "temperature['time'] = list(range(len(temperature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure = 0.2109 * (1 - 0.0065 * META['altitude'] / 288.15) ** 5.25588\n",
    "\n",
    "oxygen_profile = pvdeg.diffusion.esdiffusion(\n",
    "    temperature=temperature, \n",
    "    edge_seal='OX005', \n",
    "    encapsulant='OX003', \n",
    "    edge_seal_width=1.5, \n",
    "    encapsulant_width=10, \n",
    "    seal_nodes=20, \n",
    "    encapsulant_nodes=50, \n",
    "    press=pressure, \n",
    "    repeat=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen_profile.to_csv(\"1d-oxygen-profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(os.path.join(TEST_DATA_DIR, \"1d-oxygen-profile.csv\"), index_col=0, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "col_list = copy(res.columns).values\n",
    "col_list[21] = \"1.5\"\n",
    "\n",
    "res.columns = col_list.astype(float)\n",
    "\n",
    "res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(\n",
    "    oxygen_profile, res, \n",
    "    check_dtype=False, \n",
    "    check_column_type=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Kempe Gap Calc broken file changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pvdeg.scenario import Scenario\n",
    "from pvdeg.standards import standoff\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import pvdeg\n",
    "import json\n",
    "import pandas as pd\n",
    "import pytest\n",
    "import os\n",
    "\n",
    "# problems with scenario creating directory in test directory?\n",
    "EMAIL = \"user@mail.com\"\n",
    "API_KEY = \"DEMO_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Scenario_add():\n",
    "\n",
    "    a = Scenario(name=\"test\")\n",
    "    a.clean()\n",
    "    a.restore_credentials(email=EMAIL, api_key=API_KEY)\n",
    "    a.addLocation(lat_long=(40.63336, -73.99458))\n",
    "    a.addModule(module_name=\"test-module\")\n",
    "    a.addJob(func=standoff, func_kwarg={\"wind_factor\": 0.35})\n",
    "\n",
    "    restored = Scenario.load_json(\n",
    "        file_path=os.path.join(TEST_DATA_DIR, \"test-scenario.json\")\n",
    "    )\n",
    "\n",
    "    a.path, restored.path = None, None\n",
    "    a.file, restored.file = None, None\n",
    "\n",
    "    assert a == restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvdeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdeg.utilities.pvdeg_datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_material_special():\n",
    "\n",
    "    template_material = pvdeg.utilities.read_material(pvdeg_file=\"AApermeation\", key=\"AA000\")\n",
    "\n",
    "    assert len(template_material) == 1\n",
    "    assert \"comment\" in template_material\n",
    "\n",
    "test_read_material_special()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_material = pvdeg.utilities.read_material(pvdeg_file=\"AApermeation\", key=\"AA000\")\n",
    "\n",
    "[type(x) for x in template_material.values()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_material_normal():\n",
    "\n",
    "    res = {\n",
    "        'name': 'ST504', \n",
    "        'alias': 'PET1', \n",
    "        'contributor': 'Michael Kempe', \n",
    "        'source': 'unpublished measurements', \n",
    "        'Fickian': True,\n",
    "        'Ead': 47.603, \n",
    "        'Do': 0.554153, \n",
    "        'Eas': -11.5918, \n",
    "        'So': 9.554366e-07, \n",
    "        'Eap': 34.2011, \n",
    "        'Po': 2128.8937\n",
    "    }\n",
    "\n",
    "    template_material = pvdeg.utilities.read_material(pvdeg_file=\"O2permeation\", key=\"OX002\")\n",
    "\n",
    "    assert template_material == res\n",
    "\n",
    "test_read_material_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_material_fewer_params():\n",
    "\n",
    "    res = {\n",
    "        'name': 'ST504', \n",
    "        'Fickian': True,\n",
    "    }\n",
    "\n",
    "    template_material = pvdeg.utilities.read_material(pvdeg_file=\"O2permeation\", key=\"OX002\", parameters=[\"name\", \"Fickian\"])\n",
    "\n",
    "    assert template_material == res\n",
    "\n",
    "test_read_material_fewer_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_material_extra_params():\n",
    "\n",
    "    res = {\n",
    "        'namenotindict1': None,\n",
    "        'namenotindict2': None,\n",
    "    }\n",
    "\n",
    "    template_material = pvdeg.utilities.read_material(pvdeg_file=\"O2permeation\", key=\"OX002\", parameters=[\"namenotindict1\", \"namenotindict2\"])\n",
    "\n",
    "    assert template_material == res\n",
    "\n",
    "\n",
    "test_read_material_extra_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search_json():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pvdeg_file should override fp if both are provided\n",
    "def test_read_material_fp_override():\n",
    "\n",
    "    res = {\n",
    "        'name': 'ST504', \n",
    "        'alias': 'PET1', \n",
    "        'contributor': 'Michael Kempe', \n",
    "        'source': 'unpublished measurements', \n",
    "        'Fickian': True,\n",
    "        'Ead': 47.603, \n",
    "        'Do': 0.554153, \n",
    "        'Eas': -11.5918, \n",
    "        'So': 9.554366e-07, \n",
    "        'Eap': 34.2011, \n",
    "        'Po': 2128.8937\n",
    "    }\n",
    "\n",
    "    from pvdeg import DATA_DIR\n",
    "\n",
    "    # pass pvdeg file and it gets overridden by the file path\n",
    "    template_material = pvdeg.utilities.read_material(\n",
    "        pvdeg_file=\"O2permeation\", \n",
    "        fp=os.path.join(DATA_DIR, \"AApermeation.json\"), \n",
    "        key=\"OX002\",\n",
    "    )\n",
    "\n",
    "    assert template_material == res\n",
    "\n",
    "test_read_material_fp_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search_json():\n",
    "\n",
    "    name_res = pvdeg.utilities.search_json(pvdeg_file=\"H2Opermeation\", name_or_alias=\"Ethylene Vinyl Acetate\")\n",
    "    alias_res = pvdeg.utilities.search_json(pvdeg_file=\"H2Opermeation\", name_or_alias=\"EVA\")\n",
    "\n",
    "    assert name_res == \"W001\"\n",
    "    assert alias_res == \"W001\"\n",
    "\n",
    "test_search_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Failed",
     "evalue": "Invalid regex pattern provided to 'match': incomplete escape \\U at position 46",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailed\u001b[0m                                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m invalid_name_or_alias \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamenotindict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m expected_error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_or_alias: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvalid_name_or_alias\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in JSON at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR,\u001b[38;5;250m \u001b[39mpvdeg\u001b[38;5;241m.\u001b[39mutilities\u001b[38;5;241m.\u001b[39mpvdeg_datafiles[pvdeg_file])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpytest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraises\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mValueError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_error_message\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     11\u001b[0m     pvdeg\u001b[38;5;241m.\u001b[39mutilities\u001b[38;5;241m.\u001b[39msearch_json(pvdeg_file\u001b[38;5;241m=\u001b[39mpvdeg_file, name_or_alias\u001b[38;5;241m=\u001b[39minvalid_name_or_alias)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tford\\AppData\\Local\\miniconda3\\envs\\deg\\lib\\site-packages\\_pytest\\python_api.py:997\u001b[0m, in \u001b[0;36mRaisesContext.__init__\u001b[1;34m(self, expected_exception, message, match_expr)\u001b[0m\n\u001b[0;32m    995\u001b[0m     re_error \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m re_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m     \u001b[43mfail\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInvalid regex pattern provided to \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mre_error\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tford\\AppData\\Local\\miniconda3\\envs\\deg\\lib\\site-packages\\_pytest\\outcomes.py:178\u001b[0m, in \u001b[0;36mfail\u001b[1;34m(reason, pytrace)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Explicitly fail an executing test with the given message.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m:param reason:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    The exception that is raised.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Failed(msg\u001b[38;5;241m=\u001b[39mreason, pytrace\u001b[38;5;241m=\u001b[39mpytrace)\n",
      "\u001b[1;31mFailed\u001b[0m: Invalid regex pattern provided to 'match': incomplete escape \\U at position 46"
     ]
    }
   ],
   "source": [
    "from pvdeg import DATA_DIR\n",
    "\n",
    "pvdeg_file = \"H2Opermeation\"\n",
    "invalid_name_or_alias = \"namenotindict\"\n",
    "expected_error_message = (\n",
    "    rf\"name_or_alias: {invalid_name_or_alias} not in JSON at \"\n",
    "    rf\"{os.path.join(DATA_DIR, pvdeg.utilities.pvdeg_datafiles[pvdeg_file])}\"\n",
    ")\n",
    "\n",
    "with pytest.raises(ValueError, match=expected_error_message):\n",
    "    pvdeg.utilities.search_json(pvdeg_file=pvdeg_file, name_or_alias=invalid_name_or_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'invalid_name_or_alias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m expected_error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_or_alias: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvalid_name_or_alias\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in JSON at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR,\u001b[38;5;250m \u001b[39mpvdeg\u001b[38;5;241m.\u001b[39mutilities\u001b[38;5;241m.\u001b[39mpvdeg_datafiles[pvdeg_file])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'invalid_name_or_alias' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "expected_error_message = (\n",
    "    rf\"name_or_alias: {invalid_name_or_alias} not in JSON at \"\n",
    "    rf\"{os.path.join(DATA_DIR, pvdeg.utilities.pvdeg_datafiles[pvdeg_file])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name_or_alias: namenotindict not in JSON at C:\\\\Users\\\\tford\\\\dev\\\\PVDegradationTools\\\\pvdeg\\\\data\\\\H2Opermeation.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpvdeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvdeg_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpvdeg_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_or_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_name_or_alias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\dev\\PVDegradationTools\\pvdeg\\utilities.py:1437\u001b[0m, in \u001b[0;36msearch_json\u001b[1;34m(pvdeg_file, fp, name_or_alias)\u001b[0m\n\u001b[0;32m   1434\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (subdict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m name_or_alias \u001b[38;5;129;01mor\u001b[39;00m subdict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malias\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m name_or_alias):\n\u001b[0;32m   1435\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m key\n\u001b[1;32m-> 1437\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_or_alias: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_or_alias\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in JSON at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath(fp)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "pvdeg.utilities.search_json(pvdeg_file=pvdeg_file, name_or_alias=invalid_name_or_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
