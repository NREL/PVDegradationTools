{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# TEST\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pvdeg\n",
    "from pytest import approx\n",
    "from pvdeg import TEST_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(os.path.join(TEST_DATA_DIR,\"weather_\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSM_FILE = os.path.join(TEST_DATA_DIR, r\"psm3_pytest.csv\")\n",
    "weather_df, meta = pvdeg.weather.read(PSM_FILE, \"psm\")\n",
    "\n",
    "weather_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pvdeg\n",
    "from pytest import approx\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "\n",
    "# Load weather data\n",
    "WEATHER = pd.read_csv(\n",
    "    os.path.join(TEST_DATA_DIR, \"weather_day_pytest.csv\"), index_col=0, parse_dates=True\n",
    ")\n",
    "with open(os.path.join(TEST_DATA_DIR, \"meta.json\"), \"r\") as file:\n",
    "    META = json.load(file)\n",
    "\n",
    "# Load expected results\n",
    "rh_expected = pd.read_csv(\n",
    "    os.path.join(TEST_DATA_DIR, \"input_day_pytest.csv\"), index_col=0, parse_dates=True\n",
    ")\n",
    "rh_cols = [col for col in rh_expected.columns if \"RH\" in col]\n",
    "rh_expected = rh_expected[rh_cols]\n",
    "\n",
    "\n",
    "def test_module():\n",
    "    \"\"\"\n",
    "    test pvdeg.humidity.calc_rel_humidity\n",
    "\n",
    "    Requires:\n",
    "    ---------\n",
    "    weather dataframe and meta dictionary\n",
    "    \"\"\"\n",
    "    result = pvdeg.humidity.module(WEATHER, META)\n",
    "    pd.testing.assert_frame_equal(result, rh_expected, check_dtype=False)\n",
    "\n",
    "\n",
    "def test_psat():\n",
    "    \"\"\"\n",
    "    test pvdeg.humidity.psat\n",
    "\n",
    "    Requires:\n",
    "    ---------\n",
    "    weahter dataframe and meta dictionary\n",
    "    \"\"\"\n",
    "    psat_avg = pvdeg.humidity.psat(temp=WEATHER[\"temp_air\"])[1]\n",
    "    assert psat_avg == approx(0.47607, abs=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_psat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvdeg\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "\n",
    "GEO_META = pd.read_csv(os.path.join(TEST_DATA_DIR, \"summit-meta.csv\"), index_col=0)\n",
    "with open(os.path.join(TEST_DATA_DIR, \"summit-weather.pkl\"), \"rb\") as f:\n",
    "    GEO_WEATHER = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autotemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotemplate_result = pvdeg.geospatial.auto_template(\n",
    "    func=pvdeg.humidity.module, ds_gids=GEO_WEATHER\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_template = xr.open_dataset(\n",
    "    os.path.join(TEST_DATA_DIR, \"humidity_template.nc\")\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datasets(ds1: xr.Dataset, ds2: xr.Dataset, atol=1e-10) -> bool:\n",
    "    \"\"\"Compare loaded datasets with \"empty-like\" values\"\"\"\n",
    "\n",
    "    if ds1.dims != ds2.dims:\n",
    "        return False\n",
    "\n",
    "    if set(ds1.coords.keys()) != set(ds2.coords.keys()):\n",
    "        return False\n",
    "\n",
    "    for coord in ds1.coords:\n",
    "        if ds1.coords[coord].dtype.kind in {\"i\", \"f\"}:\n",
    "            # Use np.allclose for numeric coordinates\n",
    "            if not np.allclose(ds1.coords[coord], ds2.coords[coord], atol=atol):\n",
    "                return False\n",
    "        elif ds1.coords[coord].dtype.kind == \"M\":  # datetime64 type\n",
    "            # Use array equality for datetime coordinates\n",
    "            if not np.array_equal(ds1.coords[coord], ds2.coords[coord]):\n",
    "                return False\n",
    "        else:\n",
    "            if not np.array_equal(ds1.coords[coord], ds2.coords[coord]):\n",
    "                return False\n",
    "\n",
    "    if set(ds1.data_vars.keys()) != set(ds2.data_vars.keys()):\n",
    "        return False\n",
    "\n",
    "    for var in ds1.data_vars:\n",
    "        if not np.allclose(ds1[var], ds2[var], atol=atol):\n",
    "            return False\n",
    "\n",
    "    for dim in ds1.dims:\n",
    "        if not ds1.indexes[dim].equals(ds2.indexes[dim]):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pvdeg.utilities.compare_datasets(autotemplate_result, humidity_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    \"RH_surface_outside\": (\"gid\", \"time\"),\n",
    "    \"RH_front_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_back_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_backsheet\": (\"gid\", \"time\"),\n",
    "}\n",
    "\n",
    "manual_template = pvdeg.geospatial.output_template(\n",
    "    shapes=shapes, ds_gids=GEO_WEATHER\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdeg.utilities.compare_datasets(manual_template, humidity_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test template\n",
    "\n",
    "shapes = {\"testA\": (\"gid\",), \"testB\": (\"gid\", \"time\")}\n",
    "\n",
    "template = pvdeg.geospatial.output_template(\n",
    "    shapes=shapes,\n",
    "    ds_gids=GEO_WEATHER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.to_netcdf(os.path.join(TEST_DATA_DIR, \"mismatch-template.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvdeg\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "GEO_META = pd.read_csv(os.path.join(TEST_DATA_DIR, \"summit-meta.csv\"), index_col=0)\n",
    "\n",
    "with open(os.path.join(TEST_DATA_DIR, \"summit-weather.pkl\"), \"rb\") as f:\n",
    "    GEO_WEATHER = pickle.load(f).compute().load()\n",
    "\n",
    "HUMIDITY_TEMPLATE = xr.open_dataset(\n",
    "    os.path.join(TEST_DATA_DIR, \"humidity_template.nc\"), engine=\"h5netcdf\"\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_WEATHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_WEATHER.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMIDITY_TEMPLATE.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    \"RH_surface_outside\": (\"gid\", \"time\"),\n",
    "    \"RH_front_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_back_encap\": (\"gid\", \"time\"),\n",
    "    \"RH_backsheet\": (\"gid\", \"time\"),\n",
    "}\n",
    "\n",
    "# falsely assigning chunks here\n",
    "manual_template = pvdeg.geospatial.output_template(shapes=shapes, ds_gids=GEO_WEATHER)\n",
    "\n",
    "assert pvdeg.utilities.compare_templates(manual_template, HUMIDITY_TEMPLATE)\n",
    "for k, v in manual_template.chunks.items():\n",
    "    if len(v) != 1:\n",
    "        raise ValueError(f\"\"\"\n",
    "                          Need one chunk per axis for an unchunked input\n",
    "                          dimension {k} has {len(v)} chunks.\n",
    "                          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_weather = GEO_WEATHER.chunk({\"gid\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMIDITY_TEMPLATE.chunk({\"gid\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdeg.utilities.compare_templates(chunked_template, HUMIDITY_TEMPLATE.chunk({\"gid\": 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_template = pvdeg.geospatial.auto_template(\n",
    "    ds_gids=chunked_weather, func=pvdeg.humidity.module\n",
    ")\n",
    "\n",
    "geo_res = pvdeg.geospatial.analysis(\n",
    "    weather_ds=chunked_weather,\n",
    "    meta_df=GEO_META,\n",
    "    func=pvdeg.humidity.module,\n",
    "    template=chunked_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_res = pvdeg.geospatial.analysis(\n",
    "    chunked_weather,\n",
    "    meta_df=GEO_META,\n",
    "    func=pvdeg.humidity.module,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ds = pvdeg.geospatial.analysis(\n",
    "    weather_ds=GEO_WEATHER,\n",
    "    meta_df=GEO_META,\n",
    "    func=pvdeg.standards.standoff,\n",
    ")\n",
    "\n",
    "data_var = res_ds[\"x\"]\n",
    "\n",
    "# Stack the latitude and longitude coordinates into a single dimension\n",
    "# convert to dataframe, this can be done with xr.dataset.to_dataframe as well\n",
    "stacked = data_var.stack(z=(\"latitude\", \"longitude\"))\n",
    "latitudes = stacked[\"latitude\"].values\n",
    "longitudes = stacked[\"longitude\"].values\n",
    "data_values = stacked.values\n",
    "combined_array = np.column_stack((latitudes, longitudes, data_values))\n",
    "\n",
    "res = pd.DataFrame(combined_array).dropna()\n",
    "ans = pd.read_csv(os.path.join(TEST_DATA_DIR, \"summit-standoff-res.csv\"), index_col=0)\n",
    "res.columns = ans.columns\n",
    "\n",
    "# pd.testing.assert_frame_equal(res, ans, check_dtype=False, check_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ds.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion TESTing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import pvdeg\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER = pd.read_csv(\n",
    "    os.path.join(TEST_DATA_DIR, \"weather_day_pytest.csv\"), index_col=0, parse_dates=True\n",
    ")\n",
    "with open(os.path.join(TEST_DATA_DIR, \"meta.json\"), \"r\") as file:\n",
    "    META = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "META"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = pvdeg.temperature.temperature(\n",
    "    weather_df=WEATHER,\n",
    "    meta=META,\n",
    "    cell_or_mod=\"module\", \n",
    "    temp_model=\"sapm\",\n",
    "    conf=\"open_rack_glass_polymer\",\n",
    ")\n",
    "\n",
    "temperature = pd.DataFrame(temperature, columns = ['module_temperature'])\n",
    "temperature['time'] = list(range(len(temperature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure = 0.2109 * (1 - 0.0065 * META['altitude'] / 288.15) ** 5.25588\n",
    "\n",
    "oxygen_profile = pvdeg.diffusion.esdiffusion(\n",
    "    temperature=temperature, \n",
    "    edge_seal='OX005', \n",
    "    encapsulant='OX003', \n",
    "    edge_seal_width=1.5, \n",
    "    encapsulant_width=10, \n",
    "    seal_nodes=20, \n",
    "    encapsulant_nodes=50, \n",
    "    press=pressure, \n",
    "    repeat=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen_profile.to_csv(\"1d-oxygen-profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(os.path.join(TEST_DATA_DIR, \"1d-oxygen-profile.csv\"), index_col=0, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "col_list = copy(res.columns).values\n",
    "col_list[21] = \"1.5\"\n",
    "\n",
    "res.columns = col_list.astype(float)\n",
    "\n",
    "res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(\n",
    "    oxygen_profile, res, \n",
    "    check_dtype=False, \n",
    "    check_column_type=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Kempe Gap Calc broken file changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pvdeg.scenario import Scenario\n",
    "from pvdeg.standards import standoff\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import pvdeg\n",
    "import json\n",
    "import pandas as pd\n",
    "import pytest\n",
    "import os\n",
    "\n",
    "# problems with scenario creating directory in test directory?\n",
    "EMAIL = \"user@mail.com\"\n",
    "API_KEY = \"DEMO_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Scenario_add():\n",
    "\n",
    "    a = Scenario(name=\"test\")\n",
    "    a.clean()\n",
    "    a.restore_credentials(email=EMAIL, api_key=API_KEY)\n",
    "    a.addLocation(lat_long=(40.63336, -73.99458))\n",
    "    a.addModule(module_name=\"test-module\")\n",
    "    a.addJob(func=standoff, func_kwarg={\"wind_factor\": 0.35})\n",
    "\n",
    "    restored = Scenario.load_json(\n",
    "        file_path=os.path.join(TEST_DATA_DIR, \"test-scenario.json\")\n",
    "    )\n",
    "\n",
    "    a.path, restored.path = None, None\n",
    "    a.file, restored.file = None, None\n",
    "\n",
    "    assert a == restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvdeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdeg.utilities.pvdeg_datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_material_special():\n",
    "\n",
    "    template_material = pvdeg.utilities.read_material(pvdeg_file=\"AApermeation\", key=\"AA000\")\n",
    "\n",
    "    assert len(template_material) == 1\n",
    "    assert \"comment\" in template_material\n",
    "\n",
    "test_read_material_special()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_material = pvdeg.utilities.read_material(pvdeg_file=\"AApermeation\", key=\"AA000\")\n",
    "\n",
    "[type(x) for x in template_material.values()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_material_normal():\n",
    "\n",
    "    res = {\n",
    "        'name': 'ST504', \n",
    "        'alias': 'PET1', \n",
    "        'contributor': 'Michael Kempe', \n",
    "        'source': 'unpublished measurements', \n",
    "        'Fickian': True,\n",
    "        'Ead': 47.603, \n",
    "        'Do': 0.554153, \n",
    "        'Eas': -11.5918, \n",
    "        'So': 9.554366e-07, \n",
    "        'Eap': 34.2011, \n",
    "        'Po': 2128.8937\n",
    "    }\n",
    "\n",
    "    template_material = pvdeg.utilities.read_material(pvdeg_file=\"O2permeation\", key=\"OX002\")\n",
    "\n",
    "    assert template_material == res\n",
    "\n",
    "test_read_material_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_material_fewer_params():\n",
    "\n",
    "    res = {\n",
    "        'name': 'ST504', \n",
    "        'Fickian': True,\n",
    "    }\n",
    "\n",
    "    template_material = pvdeg.utilities.read_material(pvdeg_file=\"O2permeation\", key=\"OX002\", parameters=[\"name\", \"Fickian\"])\n",
    "\n",
    "    assert template_material == res\n",
    "\n",
    "test_read_material_fewer_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_material_extra_params():\n",
    "\n",
    "    res = {\n",
    "        'namenotindict1': None,\n",
    "        'namenotindict2': None,\n",
    "    }\n",
    "\n",
    "    template_material = pvdeg.utilities.read_material(pvdeg_file=\"O2permeation\", key=\"OX002\", parameters=[\"namenotindict1\", \"namenotindict2\"])\n",
    "\n",
    "    assert template_material == res\n",
    "\n",
    "\n",
    "test_read_material_extra_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search_json():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pvdeg_file should override fp if both are provided\n",
    "def test_read_material_fp_override():\n",
    "\n",
    "    res = {\n",
    "        'name': 'ST504', \n",
    "        'alias': 'PET1', \n",
    "        'contributor': 'Michael Kempe', \n",
    "        'source': 'unpublished measurements', \n",
    "        'Fickian': True,\n",
    "        'Ead': 47.603, \n",
    "        'Do': 0.554153, \n",
    "        'Eas': -11.5918, \n",
    "        'So': 9.554366e-07, \n",
    "        'Eap': 34.2011, \n",
    "        'Po': 2128.8937\n",
    "    }\n",
    "\n",
    "    from pvdeg import DATA_DIR\n",
    "\n",
    "    # pass pvdeg file and it gets overridden by the file path\n",
    "    template_material = pvdeg.utilities.read_material(\n",
    "        pvdeg_file=\"O2permeation\", \n",
    "        fp=os.path.join(DATA_DIR, \"AApermeation.json\"), \n",
    "        key=\"OX002\",\n",
    "    )\n",
    "\n",
    "    assert template_material == res\n",
    "\n",
    "test_read_material_fp_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search_json():\n",
    "\n",
    "    name_res = pvdeg.utilities.search_json(pvdeg_file=\"H2Opermeation\", name_or_alias=\"Ethylene Vinyl Acetate\")\n",
    "    alias_res = pvdeg.utilities.search_json(pvdeg_file=\"H2Opermeation\", name_or_alias=\"EVA\")\n",
    "\n",
    "    assert name_res == \"W001\"\n",
    "    assert alias_res == \"W001\"\n",
    "\n",
    "test_search_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pvdeg import DATA_DIR\n",
    "\n",
    "pvdeg_file = \"H2Opermeation\"\n",
    "invalid_name_or_alias = \"namenotindict\"\n",
    "expected_error_message = (\n",
    "    rf\"name_or_alias: {invalid_name_or_alias} not in JSON at \"\n",
    "    rf\"{os.path.join(DATA_DIR, pvdeg.utilities.pvdeg_datafiles[pvdeg_file])}\"\n",
    ")\n",
    "\n",
    "with pytest.raises(ValueError, match=expected_error_message):\n",
    "    pvdeg.utilities.search_json(pvdeg_file=pvdeg_file, name_or_alias=invalid_name_or_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "expected_error_message = (\n",
    "    rf\"name_or_alias: {invalid_name_or_alias} not in JSON at \"\n",
    "    rf\"{os.path.join(DATA_DIR, pvdeg.utilities.pvdeg_datafiles[pvdeg_file])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdeg.utilities.search_json(pvdeg_file=pvdeg_file, name_or_alias=invalid_name_or_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvdeg\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_res_dict(weather_df, meta):\n",
    "    \"\"\"\n",
    "    geospatial test function. returns have mixed dimensions. the first is a timeseries, the second is a float.\n",
    "    This function is meant to discover problems with geospatial.analysis and its subroutines.\n",
    "\n",
    "    .. code_block : Python \n",
    "\n",
    "        Shapes = {\n",
    "            \"temperatures\" : (\"gid\", \"time\"),\n",
    "            \"avg_temp\" : (\"gid\", ),\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    timeseries_df = pd.DataFrame(pvdeg.temperature.module(weather_df, meta))\n",
    "    avg_temp = timeseries_df[0].mean()\n",
    "\n",
    "    return {'temperatures' : timeseries_df, 'avg_temp' : avg_temp}\n",
    "    # return timeseries_df, avg_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_WEATHER.isel(gid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset(\n",
    "    data_vars={\n",
    "        \"temperatures\" : (('time'), np.full((8760,), fill_value=80)),\n",
    "        \"avg_temp\": 80\n",
    "    },\n",
    "    coords={\n",
    "        'time' : pd.date_range(start=\"2001-01-01\", periods=8760, freq='1h')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_res_dict(\n",
    "    GEO_WEATHER.isel(gid=0).to_dataframe(),\n",
    "    GEO_META.iloc[0].to_dict(),\n",
    ")['temperatures'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset(\n",
    "    data_vars= {\n",
    "        'temperatures' : timeseries_df, \n",
    "        'avg_temp' : avg_temp\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_WEATHER = xr.load_dataset(os.path.join(pvdeg.TEST_DATA_DIR, \"summit-weather.nc\"))\n",
    "GEO_META = pd.read_csv(os.path.join(pvdeg.TEST_DATA_DIR, \"summit-meta.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = pvdeg.geospatial.output_template(\n",
    "    ds_gids=GEO_WEATHER,\n",
    "    shapes={\n",
    "        'temperatures': ('gid', 'time'),\n",
    "        'avg_temp' : ('gid',),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_res_dataset(weather_df, meta):\n",
    "    \"\"\"\n",
    "    geospatial test function. returns have mixed dimensions. which are correctly stored in a xr.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    return xr.Dataset(\n",
    "        data_vars={\n",
    "            \"temperatures\" : (('time'), np.full((8760,), fill_value=80)),\n",
    "            \"avg_temp\": 80\n",
    "        },\n",
    "        coords={\n",
    "            'time' : pd.date_range(start=\"2001-01-01\", periods=8760, freq='1h')\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = pvdeg.geospatial.output_template(\n",
    "    ds_gids=GEO_WEATHER,\n",
    "    shapes={\n",
    "        'temperatures': ('gid', 'time'),\n",
    "        'avg_temp' : ('gid',),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "pvdeg.geospatial.analysis(\n",
    "    weather_ds=GEO_WEATHER,\n",
    "    meta_df=GEO_META,\n",
    "    func=mixed_res_dataset,\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in patcher\n",
      "in patcher\n"
     ]
    }
   ],
   "source": [
    "from pvdeg import Scenario\n",
    "import numpy as np\n",
    "import os\n",
    "from pvdeg import TEST_DATA_DIR\n",
    "import pvdeg\n",
    "from pvdeg.standards import standoff\n",
    "\n",
    "def mocker_addLocation(self, *args, **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    mocker function to be monkey patched at runtime for Scenario.addLocation to avoid psm3 api calls and use local weather files instead.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"in patcher\")\n",
    "\n",
    "    PSM_FILE = os.path.join(TEST_DATA_DIR, r\"psm3_pytest.csv\")\n",
    "    weather_df, meta = pvdeg.weather.read(PSM_FILE, \"psm\")\n",
    "\n",
    "    self.email, self.api_key = None, None\n",
    "\n",
    "    self.lat_long = (-999, -999)\n",
    "    self.weather_data = weather_df\n",
    "    self.meta_data = meta\n",
    "    self.gids = np.asanyarray([1245357])\n",
    "\n",
    "\n",
    "### monkey patch ###\n",
    "Scenario.addLocation = mocker_addLocation\n",
    "\n",
    "a = Scenario(name=\"test\")\n",
    "\n",
    "EMAIL = \"placeholder@email.xxx\",\n",
    "API_KEY =  \"fake_key\"\n",
    "\n",
    "a.clean()\n",
    "a.restore_credentials(email=EMAIL, api_key=API_KEY)\n",
    "a.addLocation(lat_long=(40.63336, -73.99458))\n",
    "a.addModule(module_name=\"test-module\")\n",
    "a.addJob(func=standoff, func_kwarg={\"wind_factor\": 0.35})\n",
    "\n",
    "restored = Scenario.load_json(\n",
    "    file_path=os.path.join(TEST_DATA_DIR, \"test-scenario.json\")\n",
    ")\n",
    "\n",
    "a.path, restored.path = None, None\n",
    "a.file, restored.file = None, None\n",
    "\n",
    "assert a == restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in a.__dict__.keys():\n",
    "    print(attr)\n",
    "    assert getattr(a, attr) == getattr(restored, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in patcher\n",
      "The array tilt angle was not provided, therefore the latitude tilt of 39.7 was used.\n",
      "The array azimuth was not provided, therefore an azimuth of 180.0 was used.\n"
     ]
    }
   ],
   "source": [
    "Scenario.addLocation = mocker_addLocation\n",
    "\n",
    "a = Scenario.load_json(\n",
    "    file_path=os.path.join(TEST_DATA_DIR, \"test-scenario.json\"),\n",
    "    email=EMAIL,\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "a.run()\n",
    "\n",
    "res_df = a.results[\"test-module\"][\"GLUSE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>T98_0</th>\n",
       "      <th>T98_inf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.008636</td>\n",
       "      <td>77.038644</td>\n",
       "      <td>50.561112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x      T98_0    T98_inf\n",
       "0  2.008636  77.038644  50.561112"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
